## Scalability

### Scaling with AWS
- Serverless db option
	- Can seperate db memory from compute resources (for connections/cache)
 	- Pay per second for usage, rather than static cost for dedicated server
- Recommend **starting with SQL db schema**
	- Well established technology
 	- Won't break SQL db with first million users
  	- Clear patterns to scalability
- NoSQL if:
	- Need super-low latency
 	- Metadata-driven datasets
  	- Massive amounts of data (> 5 TB)
  	- Highly non-relational data or NEED schema-less construct
- Amazon Cognito: handles Authorization and Authentication
- Horizontal scaling may be limited by licenses
- Recommend starting with AWS App Load Balancer:
	- Highly available, health checks, sticky sessions, monitor/logging, content-based routing, containerized apps, web sockets, HTTP/2
- WebSocket protocol begins with HTTP handshake to establish the connection,then upgraded to a WebSocket
	- Once established, both client and server can send/receive messages independently, facilitating low-latency, real-time interactions
- Databases can be scaled using read replicas and secondary write instances
- Use Amazon CloudFront (CDN) and S3 to serve static content (and also dynamic content in some cases)
- Amazon ElastiCache: store results of db query in-memory
- DynamoDB table: factor out schema-less, metadata into NoSQL option to free up RDS instance for other things
- AutoScaling resizes resources based on demand
	- Amazon CloudWatch can provide metrics to scale appropriately
- AWS Systems Manager allows automation of operational tasks
- To achieve a MSA or SOA (Service-Oriented Architecture): break out discrete services into their own classes/services and host them as individual containers (ECS/EKS)
	- Allows you to scale resources seperately for each service
 	- For very lightweight services, can use AWS Lambda to run functions as code
- Amazon SQS/SNS: implement queing or notification into system to allow for loose-coupling and inter-service communication
	- Allows for event-driven architecture: topics in a queue trigger specific business logic
- Cache data both inside (ElastiCache) and outside (CloudFront) your infrastructure

### Clones:
- Scalable web apps have multiple servers running the same codebase
- Each server must be identical, therefore cannot store any user or session data
- Data should be stored on a centrally managed database or persistent cache
	- Redis is a good option for cache
	- This central database/cache server should be in or near the datacenter hosting the servers for optimal performance
- Kubernetes/Docker can be sued to insure consistent deployment across different server nodes
- Amazon Machine Images (AMI): These are pre-configured virtual machine templates used to launch EC2 instances. If you're running Docker containers on EC2, an AMI ensures that all instances start with the same base configuration.
  
### Database:
- After awhile, applications with a lot of requests may eventually slow down and break altogether.  This is often a result of the MySQL database schema
	- Use a NoSQL database like MongoDB
	- Joins will now need to be done in your application code
![image](https://github.com/user-attachments/assets/31dc1ec5-5fc2-4325-ae5c-6e98f7f99641)

### Caching:
- Stores data in a key-value pair framework in the servers RAM
- Data retrieval should first check the cache, only when that is not available should it query the database
- Cache is much faster due to holding the dataset in RAM
- Redis or Memcache are the appropriate choices
- Cached Database Queries:
	- Store common database queries in RAM as cache
 	- Hashed version of the query is the cache key
  	- Drawback: when one piece of data changes (ie a table cell), you must delete all cached queries that may include that cell. This is difficult for complex queries
- Cached Objects:
	- Let the class assemble a dataset from the database and cache an instance of the class or the assembled dataset
 	- This allows you to easily remove the object whenever something changes
  	- Makes asynchronous processing possible
  		- Application just consumes the latest cached object and rarely needs to touch the database directly
  	 - Objects to cache:
  	 	- user sessions (never use the database!)
		- fully rendered blog articles
		- activity streams
		- user<->friend relationships
- Redis vs Memcache:
	- Redis has persistence, built-in data structures (lists and sets), and is more memory efficient
	- Memcache is highly scalable, has multithreading, simpler API
	
### Asynchronism
- Async paradigm #1: do the time consuming work in advance and serve the finished product with a low request time
	- Ie generate the html of large web pages in advance using a backend or script and serve the static html
- Async paradigm #2: use a job queue and multiple worker nodes on the backend to process jobs
	- A computationally intensive task is requested by the user
 	- This job is sent to a queue on the backend while the user continues to browse the page
  	- Worker nodes are constantly checking the queue for new jobs, and when one is available they pick it up and execute
  	- When the job is complete, a signal is sent to the front end and the product is served
 
### Web Hosting
- What to look for:
	- SFTP vs FTP: need to have user info and passwords encrypted
 	- Shared host vs virtual private server (VPS)
		- VPS: you get your own slice of the server in an isolated enviornment
  		- Means you don't need to contend for resources
		- Data will still not be private from the web hosting company itself (can reboot machine in single user mode)
- Scaling:
	- Vertical: add more RAM or performance per machine
 		- Only can upgrade machines so much
   		- Solid State Drives (SSDs): provide faster disk writing operations, good for database servers; smaller storage size
 	- Horizontal: add more servers
  		- Load balancer disdistributes inbound requests across webservers
    			- Can return ip address of load balancer not individual servers
				- Can have private ip addresses for servers
      			- Return ip address of a different server each time
- Load balancing
	- AWS Elastic Load Balancer is one common software solution
	- Round robin:
		- Processing load is not evenly distributed across servers
		- Ip addresses from DNS request get cached by browser/OS, leading to the same server getting returned each time
		- Let load balancer do the round robin to get around ip caching
	- Sessions will break with this model, one server may have a session and when you get redirected to a new server it will not have session data
	- How to resolve sticky session problem: visiting a site multiple still leads to the same session data and same backend server
 		- Cookies: a small piece of data that a website/server stores on your device through your web browser
   			- Can store a hash of the server's ip or id in the cookie during the initial user request
      			- This then gets sent back to the load balancer during subsequent requests
         		- The load balancer then uses this hash to discern the server ip address with the user's session
   		- Caching: can store a user's session data in RAM
     			- Due to RAM constraints, cache can get too large for the machine
       			- Can use something like an LRU cache to clear out the oldest objects (linked list)
	- Load balancers also come with redundancy (Active-Active or Active-Passive) to reduce single point of failure
 		- Heartbeats between balancers to determine status
- MySQL storage:
	- Archive engine: automatically compresses data by default
		- Slower to query but uses less disk space
   		- Useful for log files, where database writes are common but rarely need to query the data
   	- Replication:
   		- Master-Slave:
   	 		- Master is written and read from but replicates data to slaves for redundancy
   	   		- Can specialize slaves for specific operations (read vs write) to increase performance
   	     		- Still single point of failure on master
		- Master-Master:
   			- Increases redundancy to eliminate single point of failure
   	  		- Heartbeats between servers to determine status
   	    		- Requires consistent replication/synchronization
- Partitioning: allows the load balancers or servers to handle parts of the workload based on logical divisions
	- Ie users A-M on one cluster and users N-Z in another
 	- Increases performance and redundancy
- High availability is the idea of servers/databases checking eachother for heartbeats to ensure minimal downtime
	- In addition to scalability, redundancy is critical to reducing single point of failures
 	- Need redundancy in web servers, database servers, load balancers, switches, and datacenters!
  	- Availability zones that AWS provides takes care of redundancy for datacenters
  	- DNS can provide load balancing for different datacenters based on geographical location
- Security:
	- Firewall only allows TCP.80 and 443 connections
 		- TCP 80 is default port for HTTP traffic and port 443 is default port for SSL (HTTPS traffic)
   		- May want to allow port 22 for ssh or SSL based VPN for connecting to datacenter remotely
	- Traffic from load balancers to web servers is TCP 80 only
 		- Less of a need to encrypt traffic once its within the datacenter
	- Expensive load balancers up front can handle cryptogrophy and SSL certs
 	- Traffic from web servers to databases are TCP 3306 (SQL queries)
  	- Switch can typically handle firewall concerns
  	- Principal of least privilege implies we want to limit access wherever possible 

### High Level Trade-Offs
- Performance vs Scalability:
    - Scalability: adding more resources leads to a proportional increase in performance
    - Performance: handling more or larger units of work
    - For high availability, good scalability means adding more resources to facilitate redundancy does not lead to a loss of performance
    - More requests, larger datasets, or additional nodes for redundancy can impact code performance
    - Heterogeneity: some nodes will be able to process faster or store more data than other nodes in a system
        - This can be due to newer/better hardware becoming available for some nodes
        - Algorithms that rely on uniformity either break down under these conditions or underutilize the newer resources
    - Must architect programs early on to account for scalability concerns
- Latency vs Throughput:
    - Latency: time to perform some action or to produce some result
    - Throughput: number of such actions or results per unit of time
    - Generally, you should aim for maximal throughput with acceptable latency
- Availability vs Consistency:
    - Consistency: every read receives the most recent write or an error
    - Availability: every request receives a response, without guarantee that it contains the most recent version of the information
    - Partition Tolerance: the system continues to operate despite arbitrary partitioning due to network failures
    - CAP Theorem states: in a distributed system, you can only have two out of the following three guarantees across a write/read pair
        - Consistency, Availability, and Partition Tolerance
        - Networks are unreliable, must tolerate partitions
    - CP: consistency and partition tolerance
        - Waiting for a response from the partitioned node might result in a timeout error.
        - CP is a good choice if your business needs require atomic reads and writes.
    - AP: availability and partition tolerance
        - Responses return the most readily available version of the data available on any node, which might not be the latest.
        - Writes might take some time to propagate when the partition is resolved.
        - AP is a good choice if the business needs to allow for eventual consistency or when the system needs to continue working despite external errors.
    - Eventual consistency: rely on a background process to synchcronize data between servers
        - Assume some time between requests is acceptable to allow process to synchronize data
    - Consistency Patterns
        - Weak consistency: after a write, reads may or may not see it. A best effort approach is taken.
            - Seen in systems such as memcached. Works well in real time use cases such as VoIP, video chat, and realtime multiplayer games
            - Ie) if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.
        - Eventual consistency: after a write, reads will eventually see it (typically within ms). Data is replicated asynchronously.
            - Seen in systems such as DNS and email. Works well in highly available systems.
        - Strong consistency: after a write, reads will see it. Data is replicated synchronously.
            - Seen in file systems and RDBMSes. Works well in systems that need transactions.
    - Availability Patterns
        - Fail-Over:
            - Active-Passive: only active serves requests. Downtime is dependent on if passivve needs to do a hot or cold boot
            - Active-Active: application logic or DNS service needs to know of both servers
            - Disadvantages:
                - Fail-over adds more hardware and additional complexity
                - There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive
        - Replication: Master-Slave and Master-Master (discussed more in database section)
        
        <img width="272" alt="image" src="https://github.com/user-attachments/assets/129f203d-bc5d-42a1-9fb5-3a8fe0d6ab1a" />

    - Availability in parallel vs in sequence:
        - If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel
        - Sequence: overall availability decreases when two components with availability < 100% are in sequence
            - Availability (Total) = Availability (Foo) * Availability (Bar)
        - Parallel: overall availability increases when two components with availability < 100% are in parallel
            - Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
       
### DNS
![image](https://github.com/user-attachments/assets/cab327f0-c0be-4d38-ba72-b5670da2e051)
- Domain Name System (DNS): translates a domain name to an ip address
- DNS can be cached by lower-level DNS servers or by browser/OS for a certain amount of time based on TTL properties
- NS record (name server): Specifies the DNS servers for your domain/subdomain.
- MX record (mail exchange): Specifies the mail servers for accepting messages.
- A record (address): Points a name to an IP address.
- CNAME (canonical): Points a name to another name or CNAME (example.com to www.example.com) or to an A record.
- DNS services: CloudFlare, Route 53
- Different methods for routing:
    - Round robin: distributes requests cyclically across servers
    - Weighted round robin: accounts for servers with more CPU/RAM and gives those extra connections
        - Must specify weights in advance based on server specs
        - Sometimes beneficial to use this if you want to reserve one server for business critical applications (less connections)
        - Can prevent sending requests to servers under maintenance (weight=0)
    - Least connections: distribute traffic based on number of active connections rather than cyclically on new requests
    - Weighted least connections: similar to weighted round robin
    - Random: randomly assigns connections
    - Latency-based routing: use latency records to determine which connection will have the best performance
        - Route 53 DNS can accomplish this with an AWS elastic load balancer
        - Latency records are based on measurements taken over time
    - Geolocation-based: choose server based on location of users (where request originates from)
        - Localize content (like display web page in the language of the user)
        - Restrict content distribution to locations where you have distribution rights
        - Restrict endpoints by location so user's get predictably routed to the same node
        - Maps ips to a location; some ips won't be mapped though so need a default node to handle these cases
- Disadvantages:
    - Some delays from accessing a DNS, mitigated through caching
    - DNS server management could be complex and is generally managed by governments, ISPs, and large companies:
        - Level 1: root servers; highly guarded; all other DNS servers cache from these
        - Level 2: secondary servers cache from root and are thus faster; managed by govs, ISPs and companies
        - Domain name registration:
            - Register domain name registar
            - Registar sends a request to ICANN
            - Directs associated root server to add an entry based on Top Level Domain name (TLD)
            - Secondary servers cache this
        - DNS servers can be suseptible to DDoS attacks

      
### Content Delivery Network (CDN)
- Globally distributed network of proxy servers, serving content from locations closer to the user
	- Generally, static files such as HTML/CSS/JS, photos, and video
- Performance improvement through CDNs:
	- Users recieve data from datcenters close to them
 	- Your servers do not need to serve requests that the CDN fulfills
- Push CDNs: receive new content whenever changes occur on your server
	- You are responsible for getting content onto the CDN and rewriting urls to point to CDN
 	- You configure when content expires and when it is uploaded
  	- Minimizes traffic / maximizes storage
  	- Good for low traffic site, or sites whose content changes infrequently or sites with very large files
- Pull CDNs: grab new content from your server when the first user requests the content
	- Leave content on server and have CDN pull the content; rewrite urls to point to CDN
 	- Slower response time until content is cached on CDN
  	- TTL governs length of cache
  	- Minimize storage space but can create redundant traffic (if ttl expires before content changes)
  	- Works well for sites with heavy traffic and small file size
- Disadvantages:
	- CDNs can be costly, especially for high traffic (may still be worth it)
 	- Content can be stale if site is updated before TTL expires
  	- Must change urls to point to CDN
- Amazon's Cloudfront is a popular CDN choice

### Load Balancers
- Distrubute incoming client traffic to resources (databases or backend servers)
- Benefits:
    - Prevent traffic to going to unhealthy server (down or under maintenance)
    - Prevent overloading resource
    - Eliminate single point of failure
    - SSL termination: decrypt incoming requests and encrypt response to clients
        - Avoid needing to install certs on each server
        - Save from potentially expensive operations on the backend servers
    - Session persistence: track cookies and route client traffic to correct server if clients do not keep track of sessions
    - Allows for horizontal scaling
        - Adds complexity and involves cloning servers (backend or db)
        - Servers should be stateless: should not contain any user-related data like sessions or profile pictures
        - Sessions can be stored in a centralized data store such as a database (SQL, NoSQL) or a persistent cache (Redis, Memcached)
        - Downstream servers (caches and databases) need to handle more simultaneous connections as upstream servers scale out
- Use active-passive or active-active configuration w/ balancers to avoid single point of failure
- Load balancing strategies: random, round robin (or weighted), least loaded, cookies/sessions, layer 4, layer 7
- Layer 4 balancing:
    - Uses transport layer to distribute requests
    - Based on source/destination IP addresses, and ports in the header (no packet content)
    - Perform Network Address Translation (NAT): translates ip address in header
        - Private ips from internal network to/from public ips for global internet
        - Added security by concealing ips of private network
        - Expanded to NATP to include port translation as well
    - TCP/UDP traffic
- Layer 7 balancing:
    - Uses application layer to distribute requests
    - May include contents of the header, message, and cookie
    - Terminates network traffic, reads message, makes decision, then opens a connection to the selected server
        - Ie) direct video traffic to servers that host videos while directing user billing traffic to security-hardened servers
    - More computationally expensive (need to parse and read packet) but better flexibility for routing
        - Performance impact is less with modern hardware and software like NGINX
    - HTTP/HTTPS traffic
- Disadvantages:
    - Can be a bottleneck if not configured properly or does not enough resources
    - Adding load balancer increases architecture complexity (multiple even moreso)

- NGINX:
	- Traditional uses 1 thread/process per request
		- Completes an entire socket request before moving on to the next one
   		- Processes switch between cores frequently -> large overhead
  		- Spends alot of time in the blocked state for large disk read/write operations and waiting on client responses
    		- Breaks down with many connections
  	- NGINX: makes use of worker processes (1 per core) to handle multiple connections simultaneously
   		- Workers can communicate using shared memory for shared cache data or session persistence
   		- Events occur, get added to an event queue and workers pick them up and process
  	  		- Event on a listening socket -> create a connection
  	    		- Event on a connection socket -> read from buffer or write to buffer
  	        - Worker does not wait for response from client, but moves on to next request
  	        	- Client response will get added to queue and picked up by next available worker
	 	- Expensive events (read/write to disk) get offloaded to other thread managers to avoid blocking workers
  		- Workers get pinned to a CPU core, avoids context switching (processes swapping between cores)
  	 - Simple configuration, built-in caching
  	 - Great for use at the edge to handle client traffic as it enters the infrastructure
  	 	- SSL termination, serving static content, caching, reverse proxy
- HAProxy:
	- Designed specifically as a load balancer
 		- Layer 4/Layer 7 configurable
 	- Can handle millions of connections with low latency
	- Great for high TCP applications, failover resistant
 	- More complex configuration
  	- Can be used deeper in the stack:
  		- Advanced API routing, microservices, server health checks, rate limiting
- Can deploy a combined NGINX/HAProxy architecture
 	- Nginx handles web traffic at ingress: authentication, filtering of malicious traffic, serving static content
  	- HAProxy gets sanitized traffic and sends TCP data to web servers with more granular traffic control
- Dynamic vs Static load balancing algorithms
	- Static (ie weighted round robin):
 		- Assumptions are made about nature of traffic and resources without knowing state of systems at decision time
   		- Simpler to implement, less overhead, risk overloading resources
     	- Dynamic (ie least connections):
      		- Uses state of system to make optimized decisions
        	- Large complexity can slow down performance or create bottlenecks
 - https://en.wikipedia.org/wiki/Load_balancing_(computing)

### Reverse Proxy
- Web server that sits between clients and backend servers providing an interface to the public
- Forwards client requests to the appropriate web server and performs other services
- Benefits:
	- Security: hide backend ips, blacklist ips, limit number of connections per client, firewall services
 	- Scalability: clients only see proxie's ip, allows scaling or changing of backend server configuration
  	- SSL termination: decrypt/encrypt traffic reducing load on backend servers
  	- Compression: compress server responses
  	- Caching: return response for cached requests
  	- Static content: serve static content directly
- Load balancer vs Reverse proxy:
	- Load balancers are used with multiple backend servers, reverse proxies can be used with just one
 	- Nginx and HAProxy support both services

### Application Layer
<img width="1000" height="300" alt="image" src="https://github.com/user-attachments/assets/219e7b5b-ddc0-49b1-aff7-cc39557b4815" />

- Seperating out application (or platform) services from web services allow each to be scaled independently
    - New API does not necessitate new web server
    - Conforms to **single responsibility principle** -> smaller independent services working together
- Web servers should be responsible for:
    - Frontend: serving web page content (React)
    - Backend: serving serves APIs for back end to consume
- Microservices:
    - Loosely-coupled services, performing unique functions, exchanging info using a lightweight protocol
    - Pintrest services: user profile, follower, feed, search, photo upload, etc.
        - Follow service: fast access, simple map datastructure; use Redis
        - Feed service: store metadata in database and image as a blob in AWS s3 bucket; use CDN like CloudFront to cache images
        - Search service: index from all data sources for search; ElasticSearch service is a good choice
        - Spam service: used supervised/unsupervised ML algorithms/libraries to filter data
    - Discovery services:
        - Consul, Etcd, and Zookeeper help services find each other by keeping track of registered names, addresses, and ports
        - Can perform health checks on services using HTTP endpoints
- Disadvantages: can add complexity
- OpenAPI provides the standard for which mircroservices talk to one another

### Database
#### Relational Database Management System (RDBMS)
- Relational database (SQL) is data organized in tables
- ACID properties of relational databases:
	- Atomicity: each transaction is all or nothing
 	- Consistency: any transaction brings db from one valid state to another
  	- Isolation: transactions concurrently = transactions in serial
  	- Durability: once transactions are committed, they stay committed
- Master-Slave Replication:
	- Master reads and writes, replicates writes to slave(s), which only serve reads
 	- Slaves can replicate to other slaves in a tree-like fashion
  	- If master goes offline, db can operate in read-only until new master is promoted or provisioned
  	- Disadvantages:
  		- Logic needed for promotion scheme
  	 	- Data loss if master fials before its replicated
  	  	- With lots of writes, slaves can get bogged down with replaying writes and will bottleneck ability to serve reads
  	  	- More slaves = more replications -> greater replication lag
  	  	- Writing to masters can support multithreading, read replicas only support writing in single threaded
  	  	- Replication -> more hardware -> more complexity
- Master-Master Replication:
	- Masters serve both read and writes and coordinate replications with one another
 	- If one goes down, the other can operate with both reads and writes
  	- Disadvantages:
  		- Same as Master-Slave (except for promotion logic)
  	 	- Necessitates load balancer or load balancing in application code
  	  	- Most systems are loosely consistent (violates ACID) or have write latency due to synchronization
  	  	- Merge conflicts increase with more write nodes/increased latency
- Federation:
	- Functional partitioning of databases (ie forums, users, products dbs)
 		- Leads to less read/write traffic to each db -> less replication lag
  	- Smaller dbs -> more data can fit in memory -> more cache hits -> better performance
  	- Multiple write dbs -> more parallel writes -> better throughput
  	- Disadvantages:
  		- Not effective if schema requires huge functions or tables
  	 	- Need to update app logic to determine which db parition to read/write
  	  	- Joining data from different dbs is more complex (use [server link](https://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers))
  	  	- More hardware = more complexity
- Sharding:
    - Similar to federation, but partitions dbs so each one holds a subset of data (ie by users names or geo location)
    - Breaks tables apart by sections of rows, reducing index size and improving performance
    - Consistent Hashing:
        - A ring is partitioned (ie 1 - 2^160)
        - Each database shard is assigned a position on the ring using its id
        - Data in the db cluster is assigned based on its hashed key
        - The hashed key returns a number, which corresponds to a position on the ring
        - The db the data is stored in is the next db on the ring moving clockwise from the hashed key value
        - Adding new nodes only means reassigning a fraction of the keys
        - <img width="530" height="362" alt="image" src="https://github.com/user-attachments/assets/e32ef915-f22e-4ecf-bdaf-3b8c569d5037" />
        - This scheme more easily avoids hotspots
            - Keys that are lexographically close to one antoher (ie keys based on time of day) will be spread out across all nodes based on hashing
        - Makes scaling up or down more predictable
            - Partitions are of fixed size and rougly even amount of data, new nodes just pick up some number of fixed partitions
        - Replication is simple as each node can have a set of partitions it is primary for and a set it is a replica for
            - Also promotes load balancing
    - Disadvantages:
        - Need to account for sharding in app logic, could lead to complex queries
        - Load may not be evenly distributed across dbs
        - Same other disadvantages as federation
        - Minimal support for sharding from online communities or toolsets
- Denormalization:
    - Add redundant copies of data in tables to avoid expensive join operations during database reads
        - Best for large read:write ratio apps, as it introduces some write overhead
    - Store computed values or combine data in a table that may be queried from multiple tables (i.e. user profile info) to speed up query performance
    - Disadvantages:
        - Data is duplicated
        - Constraints help redundant copies of data stay in sync, increases complexity
        - Heavy write DBs may be worse performing

- SQL Tuning
    - Must benchmark and profile to simulate/uncover bottlenecks
        - Benchmark: simulate high-load situations with tools like [ab](https://httpd.apache.org/docs/2.2/programs/ab.html)
        - Profile: use [slow query log](http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html) to track performance
    - Optimizations
        - Tighten up schema:
            - MySQL dumps to disk in contiguous blocks for fast access
            - Use CHAR instead of VARCHAR (for fixed length fields)
            - If you need to use VARCHAR, use VARCHAR(255) (max amount chars in an 8 bit number, no hit on performance)
            - Use TEXT for large blocks of text such as blog posts
            - Use INT for larger numbers up to 2^32
            - Use DECIMAL for currency to avoid floating point representation errors
            - Avoid storing large BLOBS, store the location of where to get the object instead
            - Set the NOT NULL constraint where applicable to improve search performance
        - Use good indices:
            - Columns that you are querying (SELECT, GROUP BY, ORDER BY, JOIN) could be faster with indices
            - Placing an index can keep the data in memory, requiring more space
            - Writes could be slower since index needs to be updated
            - When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices
        - Avoid expensive joins using denormalization
        - Partition tables: put hot spots in a separate table to keep it in memory
        - Tune the query cache: in some cases, the query cache could lead to [performance issues](https://dev.mysql.com/doc/refman/5.7/en/query-cache.html)
